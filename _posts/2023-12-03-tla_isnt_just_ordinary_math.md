---
layout: post
title:  "TLA isn't \"just ordinary math\""
date:   2023-12-03
comments: true
tag: TLA+
tag: formal verification
---

This is a rant on the "TLA is great because it's just ordinary math" claim made by Leslie Lamport, that I have seen parroted often enough to annoy me. I actually have no gripes with the first part of the sentence -- I do think that the Temporal Logic of Actions (TLA) *is* great, but I don't think it's because it's "ordinary math" and I want to explain why.

The chain of arguments that I see repeated is roughly the following:

1. Ordinary math is great at rigorously describing abstract concepts.
2. When designing algorithms and systems, the designs are abstract, so one should use ordinary math to rigorously describe them.
3. Ordinary mathematicians use first-order logic (FOL), and in particular Zermelo-Frankel (ZF) set theory, which is a theory in FOL.
4. TLA predicates are based on first-order set theory. Hence TLA is great for describing algorithms and system designs, since it's just ordinary math.

The first claim here that I disagree with is #3. While "ordinary math" can indeed be formalized in ZF (or ZFC, ZF with choice), most "ordinary mathematicians" are not logicians nor set theorists. I think my undergrad in math reflects most people's experience. You're introduced to ZF sometimes during your studies. You get to see the axioms of ZF, you get to be frightened by the encoding of the natural numbers in ZF[^encoding], and you get to be amused by the Banach-Tarski paradox. But mostly you're told that you can sleep well since what you will be doing (i.e., "real math") has a strong logical foundation based on ZF. So you can merrily go on to forget about it and never touch it again, and do stuff in analysis, algebra, discrete math, topology, probability, or what have you. You silently sneer at the logicians, who you think aren't doing any real math anyway.

Now that's not to say that an ordinary mathematician doesn't write down a lot of FOL formulas -- they do. But, in my second-hand experience of observing them throughout the years, they will much more often draw a geometrical construction, or write things like "without loss of generality", "analogously", or the venerable "it can easily be seen that". Good luck writing that last one down in FOL. So I claim that claim #3 is bogus.

See, a "working mathematician" generally operates at a much higher level of abstraction, and a lower level of formality and rigor than FOL. Or for that matter, HOL (higher-order logic), Martin-LÃ¶f's type theory, or anything other kind of formalism; any of these will feel like a bit of a straitjacket when writing down proofs. Mathematicians don't need to be completely precise, they just need to be precise enough for other mathematicians to understand them. In that sense, mathematicians like to "move fast and break things" (I didn't really expect to ever say that, but there, I said it). Now there are downsides to this, as new math proofs can hang in the limbo for years, because nobody can confidently judge their truth. Ask Grigori Perelman, whose proof of the Poincare conjecture took years to be accepted. Possibly worse is the story I heard at a lecture by the late Vladimir Voevodsky[^Voevodsky]. He recounted his experience where he had published a wrong result, which later got correctly challenged, but he incorrectly believed the challenger to be wrong, and proceeded to publish a rebuttal of the challenge, only to realize that he was wrong all along years later. And we're talking about a Fields medalist here. So we are starting to see mathematicians actually fully formalize math results. But to summarize, I just don't think that it's correct to say that TLA is just ordinary math. Is it among the simpler formal languages out there? Yes. But working with sets and functions is generally also fairly straightforward in Isabelle or Lean. In fact, "ordinary mathematicians" have used both of these extensively to write down a lot of "ordinary math". I don't think they're worse off for it compared to using a first-order formalism like TLA.

That's mostly all I had to say about the claim #3, but let me not end my rant just yet; I'd like to continue by attacking the claim #2 next. I think that using "ordinary math" to describe computer systems is suboptimal. My exhibit A is a complicated system[^canton-summary] that I was working on a few years back. While the design was complicated, I could still tease out a compact and elegant description of the main security property, a great starting point for proofs and the wet dream of a formal verification specialist. The proof on the other hand was more of a nightmare. The whole design doc spread over something like 80 pages, with ordinary math style definitions, ordinary math style theorems and ordinary math style lemmas carefully orchestrating the system's security. The whole ensemble would then start squeaking and creaking any time we'd change something in the design in order to improve any properties, simplify the implementation, or add new features. For each definition we'd write down, we'd need to think whether and how it has been affected by the change. And for each changed definition, we had to meticulously sift through all the proofs and make sure that they still hold, or adapt them. If it wasn't for colleagues with a higher level of discipline (and likely an even higher pain threshold) than yours truly who'd painstakingly recheck the proofs or force me to do so, we would've missed problems for sure. And I can't be quite certain we hadn't missed any anyways.

So I actually think that ordinary math isn't that great at handling large proofs. I think that programmers are in some sense better equipped at that, actually. At least we have things like [sane](https://en.wikipedia.org/wiki/Standard_ML#Module_system) or even [great](https://people.mpi-sws.org/~rossberg/papers/Rossberg%20-%201ML%20--%20Core%20and%20modules%20united%20%5BJFP%5D.pdf) module systems to help organize large developments well. Well some of us get to have those, at least. But perhaps even more importantly, I think that ordinary math is kind of terrible at proof maintenance. Maintenance is perhaps less of a problem in math; you will be tweaking your definitions and redoing your proofs while you're writing a paper, but after that the proofs are generally frozen. Yet computer systems are under constant development, and you'll need to change and refactor the definitions and proofs as you're doing the same with the code. And it comes to refactoring, I think that there is something to be learned from programmers, because we're refactoring all the frickin time.

I find refactoring Haskell, Rust or Scala code a *lot* more pleasant than refactoring Python code.
Which leads me to one thing that I actually don't like about TLA+ (the diatribe continues). Which is the choice of untyped (aka "unsorted") FOL for predicates, precisely the reason why TLA is claimed to be "ordinary math". The lack of types in my experience makes refactoring TLA models more painful than necessary. It's still not as bad as Python, because TLA code will likely end up being analyzed by the TLA model checker, which will eventually point out your refactoring errors. But it can take minutes, hours, or days until you get that feedback. A sensible type checker would catch that immediately.

Now in TLA's defense, this wasn't really a concern back when it was designed. Lamport designed it to be written using pen and paper, and not as a computer language. But things have evolved since then, and TLA has tool support. Now types also have downsides; there's actually an [interesting paper](https://dl.acm.org/doi/pdf/10.1145/319301.319317) where Lamport and the author of Isabelle/HOL, Lawrence Paulson, discuss the merits of types in specification languages. In my experience, the choice of types/no types isn't much different for models compared to programs. For small programs, I'll often reach for Python, as it's easy enough to keep everything in my head without having to worry about types. But for anything larger I'll prefer something with a sensible type system (modulo other practical concerns).

So why am I whining about TLA so much, given that I've been using it to write a [bunch of models](https://github.com/dfinity/tla-models) for work the last couple of years? Because a few things made it a great choice for me:

1. It's an expressive language: first-order set theory, but extended with higher-order operators, yet it comes with verification tools. This is very different from model checking systems such as SPIN/Promela, or NuSMV; their heavily restricted languages make it a pain to model many systems.
1. It has a model checker (actually, two[^tla-model-checkers] by now). So instead of writing proofs, I can write the model and let the tool check it for me. OK, it's not quite that easy, because I do spend a fair amount of time optimizing the models to get the model checking through, but still way less than I would using a full-fledged proof assistant. A proof assistant would give stronger guarantees, but I can live with the weaker ones.
1. Its main model checker (TLC) is explicit-state, meaning that it will just exhaustively enumerate all states of your system. While this is highly inefficient, it's predictably inefficient, unlike other methods involving binary decision diagrams or SMT solvers, which all contain dark magic.
1. It's a small and inextensible language, meaning that a colleague can review my models without having to spend days learning TLA. To contradict myself a bit, not having a type system does contribute to keeping the language small. But a small language is a tradeoff; no types and no syntactic extensions make it painful to write large models. But you're likely to hit the limits of TLC before your models get large enough for this to matter.
1. I think the "T" in TLA (temporal) is actually quite clever and nice. While it's hard to untangle this from the choice of first-order logic as opposed to predicate logic, I find TLA much more ergonomic to use compared to linear temporal logic (LTL). Now I think the main reason why Lamport designed the temporal part the way he did was to always allow refinement, I actually find the end result nicer regardless of refinement considerations.

You'll notice that "it's just ordinary math" is not in this list.

### Footnotes

[^encoding]: There are [different ways](https://en.wikipedia.org/wiki/Set-theoretic_definition_of_natural_numbers) to encode natural numbers in ZF. For example, with the Von Neumann encoding, you encode `0` as the empty set, and the successor of the number `N` is encoded as {% raw %}`Encoding(Suc(N)) = {{}, Encoding(N)}`{% endraw %}.
[^Voevodsky]: Voevodsky also describes the experience [here](https://www.ias.edu/sites/default/files/pdfs/publications/letter-2014-summer.pdf)
[^canton-summary]: The [system](https://canton.network) provides atomic transactions across data held by mutually mistrusting parties, with each party having only partial visibility into the transaction (so you could, for example, atomically trade securities for money, without the central securities depository knowing the price at which they were traded, nor the settlement bank knowing what was bought).
[^tla-model-checkers]: The two model checkers are the built-in TLC, and [Apalache](https://apalache.informal.systems/).
